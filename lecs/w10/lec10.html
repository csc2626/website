<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.31">

  <meta name="author" content="Florian Shkurti">
  <title>CSC2626 - Fall 2024 – CSC2626 Imitation Learning for Robotics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link rel="stylesheet" href="../style.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="CSC2626 Imitation Learning for Robotics – CSC2626 - Fall 2024">
<meta property="og:description" content="Week 10: Shared Autonomy and Human-in-the-Loop Learning">
<meta property="og:site_name" content="CSC2626 - Fall 2024">
<meta name="twitter:title" content="CSC2626 Imitation Learning for Robotics – CSC2626 - Fall 2024">
<meta name="twitter:description" content="Week 10: Shared Autonomy and Human-in-the-Loop Learning">
<meta name="twitter:card" content="summary">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">CSC2626 Imitation Learning for Robotics</h1>
  <p class="subtitle">Week 10: Shared Autonomy and Human-in-the-Loop Learning</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Florian Shkurti 
</div>
</div>
</div>

</section>
<section id="todays-agenda" class="slide level2">
<h2>Today’s agenda</h2>
<p>• Shared autonomy for assistive robotics</p>
<p>• Shared autonomy with human in the loop in deep RL</p>
<p>• Hindsight optimization and interactive goal prediction</p>
<p>• Relaxed inverse kinematics for fluid interaction with robot arms</p>

<aside><div>
<p>Acknowledgments<br>
Today’s slides are based on student presentations from 2019 by: Andrei Barsan, Bin Yang, and Tingwu Wang</p>
</div></aside></section>
<section id="section" class="slide level2">
<h2></h2>
<iframe data-external="1" src="https://www.youtube.com/embed/wjnhrzugBj4?rel=0" width="100%" height="80%" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<iframe data-external="1" src="https://www.youtube.com/embed/Wvh-uixQrGI" width="100%" height="80%" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</section>
<section id="shared-autonomy-via-deep-reinforcement-learning" class="slide level2">
<h2>Shared Autonomy via Deep Reinforcement Learning</h2>
<p>Siddharth Reddy, Anca Dragan, Sergey Levine UC Berkeley</p>
<p>Presented by Ioan Andrei Bârsan on February 22, 2019</p>
<p>iab@cs.toronto.edu</p>
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="images/shared-autonomy.jpg" class="quarto-figure quarto-figure-right" width="400" height="200"></p>
</figure>
</div>
</section>
<section id="key-question" class="slide level2">
<h2>Key Question</h2>
<p><img data-src="images/robot-hand.jpg" width="400" height="200"></p>
<p>How can a robot <strong>collaborating</strong> with a human infer the human’s goals with as few <strong>assumptions</strong> as possible?</p>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>• <strong>Hard</strong>: Actuating a robot with many DoF and/or unfamiliar dynamics.</p>
<p>• <strong>Hard</strong>: Specifying a goal formally (e.g., coordinates).</p>
<p>• <strong>Easy</strong>: Demonstrating the goal indirectly.</p>
<p>• …let the machine figure out what I want!</p>
</div><div class="column" style="width:40%;">
<p><img data-src="images/robot-chair.jpg" height="400"></p>
<div class="tiny-font">
<p>Image source: “Multihierarchical Interactive Task Planning. Application to Mobile Robotics” Galindo et al., 2008</p>
</div>
</div></div>
</section>
<section id="motivation-unknown-dynamics-are-hard-for-humans" class="slide level2">
<h2>Motivation: Unknown Dynamics are Hard for Humans</h2>

<img data-src="images/unknown-dynamics.png" class="r-stretch"></section>
<section id="it-can-get-even-worse-than-lunar-lander" class="slide level2">
<h2>It can get even worse than Lunar Lander…</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="images/lunar-lander.jpg"></p>
</div><div class="column small-math" style="width:30%;">
<p><a href="https://www.foddy.net/Athletics.html" class="uri">https://www.foddy.net/Athletics.html</a> or Google “qwop”</p>
</div></div>
</section>
<section id="challenges" class="slide level2">
<h2>Challenges</h2>
<p>• <strong>Recall</strong>: Want to demonstrate the goal indirectly with <strong>minimal assumptions</strong>.</p>
<p>• → We expect the computer to start helping <strong>while it is still learning.</strong></p>
<p>• <strong>Challenge #1</strong>: How to actually infer user’s goal?</p>
<p>• <strong>Challenge #2</strong>: How can we learn this online with low latency?</p>
</section>
<section id="main-hypothesis" class="slide level2">
<h2>Main Hypothesis</h2>
<p>Shared autonomy can improve human performance without any assumptions about:</p>
<ol type="1">
<li><p>dynamics,</p></li>
<li><p>the human’s policy,</p></li>
<li><p>the nature of the goal.</p></li>
</ol>
</section>
<section id="formulation-reward" class="slide level2">
<h2>Formulation: Reward</h2>
<p><br></p>
<p><span class="math display">\[
R(s, a, s') = \underbrace{R_{\text{general}}(s, a, s')}_{\text{known}} + \underbrace{R_{\text{feedback}}(s, a, s')}_{\text{unknown, but observed}}
\]</span></p>
<div class="small-math">
<div class="absolute" style="top: 210px; left: 100px; ">
<p><span class="math inline">\(\qquad \qquad \quad \uparrow\)</span><br>
Agent’s reward<br>
(what we want to maximize)</p>
</div>
<div class="absolute" style="top: 230px; left: 350px; ">
<p><span class="math inline">\(\qquad \qquad \qquad \uparrow\)</span><br>
Handcrafted “common sense”<br>
knowledge: do not crash, do<br>
not tip, etc.</p>
</div>
<div class="absolute" style="top: 230px; right: 150px; ">
<p><span class="math inline">\(\uparrow\)</span><br>
Stuﬀ inferred from the human<br>
(<span class="red">Main focus of this paper!</span>)</p>
</div>
</div>
</section>
<section id="formulation" class="slide level2">
<h2>Formulation</h2>
<div class="absolute" style="top: 0px; right: 0px; ">
<p><span class="math display">\[
\underbrace{R_{\text{feedback}}(s, a, s')}_{\text{unknown, but observed}}
\]</span></p>
</div>
<p><br></p>
<div class="columns">
<div class="column tiny-font" style="width:5%;">
<p><br><br></p>
<p>Needs<br>
virtual<br>
“user”!</p>
</div><div class="column" style="width:65%;">
<p>• The authors introduce three variants of their method:</p>
<ol type="1">
<li><p>Known goal space, known user policy.</p></li>
<li><p>Known goal space, unknown user policy.</p></li>
<li><p>Unknown goal space, unknown user policy.</p></li>
</ol>
</div><div class="column" style="width:30%;">
<p><img data-src="images/fewer-assumption.png"></p>
</div></div>
</section>
<section id="the-method" class="slide level2">
<h2>The Method</h2>
<ul>
<li><p>Based on Q-Learning.</p></li>
<li><p>User input has <strong>two</strong> roles:</p>
<ol type="1">
<li><p>A <strong>prior policy</strong> we should fine-tune.</p></li>
<li><p>A sensor which can be used to decode the <strong>goal</strong>.</p></li>
</ol></li>
<li><p>Short version: Like Q-Learning, but execute closest high-value action to the user’s input, instead of highest-value action.</p></li>
</ul>
</section>
<section id="the-method-continued" class="slide level2">
<h2>The Method (Continued)</h2>

<img data-src="images/method-algo1.png" class="r-stretch"></section>
<section id="the-method-continued-1" class="slide level2">
<h2>The Method (Continued)</h2>

<img data-src="images/method-2.png" class="r-stretch"></section>
<section id="but-where-is-textr_textfeedback" class="slide level2">
<h2>But where is <span class="math inline">\(\text{R}_{\text{feedback}}\)</span>?</h2>
<ul>
<li>The choice of <span class="math inline">\(\text{R}_{\text{feedback}}\)</span> determines what kind of <strong>input</strong> we give to the Q- Learning agent in addition to state!</li>
</ul>
<ol type="1">
<li><p>Known goal space &amp; user policy → exact goal.</p></li>
<li><p>Known goal space &amp; unknown policy → predicted goal (pretrained LSTM).</p></li>
<li><p>Unknown goal space &amp; policy → the user’s input <span class="green">(main focus)</span></p></li>
</ol>
</section>
<section id="input-to-rl-agent" class="slide level2">
<h2>Input to RL Agent</h2>

<img data-src="images/rl-agent.png" class="r-stretch"></section>
<section id="experiments" class="slide level2">
<h2>Experiments</h2>
<p><br><br></p>
<ul>
<li><p><strong>Virtual</strong> experiments with Lunar Lander in OpenAI gym.</p></li>
<li><p><strong>Physical</strong> experiments with an actual drone.</p></li>
</ul>
</section>
<section id="real-world-experiments" class="slide level2">
<h2>Real-World Experiments</h2>
<p><img data-src="images/realworld-ex.png" class="absolute" style="top: 50px; right: 0px; width: 300px; "></p>
<p><br></p>
<ul>
<li><p><strong>Goal</strong>: Land drone on pad <strong>facing a certain way</strong>.</p></li>
<li><p><strong>Pilot</strong>: Human, knows target orientation.</p></li>
<li><p><strong>Copilot</strong>: Our Agent, knows where pad is, but not target orientation.</p></li>
</ul>
</section>
<section id="real-world-results" class="slide level2">
<h2>Real-World Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/realworld-results.jpg" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
<p><strong>Important observation: Only n = 4 humans in drone study.</strong></p>
</section>
<section id="experimental-results-assumptions" class="slide level2">
<h2>Experimental Results: Assumptions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/ex-results-assumption.jpg" class="quarto-figure quarto-figure-center" height="400"></p>
</figure>
</div>
<ul>
<li><p>Higher alpha means we take any action. α = 1.0 means we ignore the pilot.</p></li>
<li><p>Experimented in virtual environment.</p></li>
</ul>
</section>
<section id="recap-strengths" class="slide level2">
<h2>Recap: Strengths</h2>
<ul>
<li><p>Good results even when making no assumptions about user/goal.</p></li>
<li><p>Writing is very clear!</p></li>
<li><p>Possible applications in many fields, including e.g.&nbsp;<strong>prosthetics, wheelchairs</strong>.</p></li>
<li><p>Source code released on GitHub!</p></li>
</ul>
</section>
<section id="recap-weaknesses" class="slide level2">
<h2>Recap: Weaknesses</h2>
<ul>
<li><p>User studies could have had more participants.</p></li>
<li><p>Could have shown results on more Gym environments.</p></li>
<li><p>Solution does not generalize to sophisticated long-term goals.</p></li>
</ul>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>Can do shared autonomy with minimal assumptions!</li>
<li>Idea: Q-Learning &amp; pick high-value action most similar to user’s action.</li>
<li>Works well in virtual environments (real humans).</li>
<li>Seems to work well in real environments, too.</li>
</ul>
</section>
<section id="thanks-for-your-attention" class="slide level2">
<h2>Thanks for your attention!</h2>
<p>Q&amp;A, if time permits it.</p>
<p>Project website: <a href="https://sites.google.com/view/deep-assist" class="uri">https://sites.google.com/view/deep-assist</a></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/lader-video.png" class="quarto-figure quarto-figure-center" height="300"></p>
</figure>
</div>
<p>Video of computer-assisted human piloting the lander.</p>
</section>
<section id="shared-autonomy-via-hindsight-optimization" class="slide level2">
<h2>Shared Autonomy via Hindsight Optimization</h2>
</section>
<section id="teleoperation" class="slide level2">
<h2>Teleoperation</h2>
<p><img data-src="images/teleportation1.jpg" style="width:30.0%"> <img data-src="images/teleporation2.jpg" style="width:30.0%" height="200"> <img data-src="images/teleporation3.jpg" style="width:30.0%" height="200"></p>
<p><img data-src="images/teleporation4.jpg" style="width:30.0%"> <img data-src="images/teleporation5.jpg" style="width:30.0%"> <img data-src="images/teleporation6.jpg" style="width:30.0%" height="200"></p>
<p><strong>Noisy, insuﬃcient degrees of freedom, tedious</strong></p>
<div class="tiny-font absolute" style="left: 0px; bottom: 0px; ">
<p>Image credit: Javdani RSS2015 talk</p>
</div>
</section>
<section id="shared-autonomy" class="slide level2">
<h2>Shared Autonomy</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p><img data-src="images/user-input.png"> <strong>User Input</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p>+</p>
</div><div class="column" style="width:30%;">
<p><br><br></p>
<p><img data-src="images/autonoumous.jpg"> <strong>Autonomous Assistance</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p><strong>=</strong></p>
</div><div class="column" style="width:30%;">
<p><br></p>
<p><img data-src="images/acheive-goal.jpg"> <strong>Achieve Goal</strong></p>
</div></div>
</section>
<section id="shared-autonomy-1" class="slide level2">
<h2>Shared Autonomy</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p><img data-src="images/user-input.png"> <strong>User Input</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p>+</p>
</div><div class="column" style="width:30%;">
<p><img data-src="images/autonomous-assistance.png"> <strong>Autonomous Assistance</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p><strong>=</strong></p>
</div><div class="column" style="width:30%;">
<p><br></p>
<p><img data-src="images/acheive-goal.jpg"> <strong>Achieve Goal</strong></p>
</div></div>
</section>
<section id="shared-autonomy-2" class="slide level2">
<h2>Shared Autonomy</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Predict goal Assist for single goal</p>
<div class="small-math">
<p>[Dragan and Srinivasa 13]<br>
[Kofman et al.&nbsp;05]<br>
[Kragic et al.&nbsp;05]<br>
[Yu et al.&nbsp;05]<br>
[McMullen et al.&nbsp;14]<br>
…</p>
</div>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p>+</p>
</div><div class="column" style="width:30%;">
<p><img data-src="images/autonomous-assistance.png"> <strong>Autonomous Assistance</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p><strong>=</strong></p>
</div><div class="column" style="width:30%;">
<p><br></p>
<p><img data-src="images/acheive-goal-number.png"> <strong>Achieve Goal</strong></p>
</div></div>
</section>
<section id="shared-autonomy-3" class="slide level2">
<h2>Shared Autonomy</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Predict goal Assist for single goal</p>
<div class="small-math">
<p>[Dragan and Srinivasa 13]<br>
[Kofman et al.&nbsp;05]<br>
[Kragic et al.&nbsp;05]<br>
[Yu et al.&nbsp;05]<br>
[McMullen et al.&nbsp;14]<br>
…</p>
</div>
<p>Predict goal distribution Assist for distribution</p>
<div class="small-math">
<p>[Hauser 13]<br>
This work!</p>
</div>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p>+</p>
</div><div class="column" style="width:30%;">
<p><img data-src="images/autonomous-assistance.png"> <strong>Autonomous Assistance</strong></p>
</div><div class="column" style="width:3%;">
<p><br><br><br></p>
<p><strong>=</strong></p>
</div><div class="column" style="width:30%;">
<p><br></p>
<p><img data-src="images/acheive-goal-arrow.png"> <strong>Achieve Goal</strong></p>
</div></div>
</section>
<section id="method" class="slide level2">
<h2>Method</h2>
<ul>
<li>System dynamics: <span class="math inline">\(x’ = T(x, a)\)</span></li>
</ul>
<p><img data-src="images/system-dynamics.png" class="absolute" style="bottom: 0px; right: 0px; width: 400px; "></p>
</section>
<section id="method-1" class="slide level2">
<h2>Method</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li><p>System dynamics: <span class="math inline">\(x' = T(x, a)\)</span></p></li>
<li><p>User (MDP) as <span class="math inline">\((X, U, T, C_g^{\text{usr}})\)</span></p>
<ul>
<li>User policy: <span class="math inline">\(\pi_g^{\text{usr}}(x) = p(u|x, g)\)</span></li>
<li>MaxEnt IOC: <span class="math inline">\(C_g^{\text{usr}} : X \times U \to \mathcal{R}\)</span></li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="images/system-dynamic-user.png"></p>
</div></div>
</section>
<section id="method-2" class="slide level2">
<h2>Method</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li><p>System dynamics: <span class="math inline">\(x' = T(x, a)\)</span></p></li>
<li><p>User (MDP) as <span class="math inline">\((X, U, T, C_g^{\text{usr}})\)</span></p>
<ul>
<li>User policy: <span class="math inline">\(\pi_g^{\text{usr}}(x) = p(u|x, g)\)</span></li>
<li>MaxEnt IOC: <span class="math inline">\(C_g^{\text{usr}} : X \times U \to \mathcal{R}\)</span></li>
</ul></li>
<li><p>System (POMDP) as <span class="math inline">\((S, A, T, C^{\text{rob}}, U, \Omega)\)</span></p>
<ul>
<li>Uncertainty over user’s goal</li>
<li>System state: <span class="math inline">\(s = X \times G\)</span></li>
<li>Observation: user inputs <span class="math inline">\(U\)</span></li>
<li>Observation model <span class="math inline">\(\Omega\)</span></li>
</ul>
<p><span class="math inline">\(p(g|\xi^{0 \to t}) = \frac{p(\xi^{0 \to t}|g)p(g)}{\sum_{g'} p(\xi^{0 \to t}|g')p(g')}\)</span></p>
<ul>
<li>Cost function <span class="math inline">\(C^{\text{rob}} : S \times A \times U \to \mathcal{R}\)</span></li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="images/method-goal-belief.png"></p>
</div></div>
</section>
<section id="hindsight-optimization" class="slide level2">
<h2>Hindsight Optimization</h2>
<div class="columns">
<div class="column small-math" style="width:35%;">
<ul>
<li><p>MDP solution:</p>
<p><span class="math display">\[V^{\pi^r}(s) = \mathbb{E}\left[\sum_t C^r(s_t, u_t, a_t) \mid s_0 = s\right]\]</span></p>
<p><span class="math display">\[V^*(s) = \min_{\pi^r} V^{\pi^r}(s)\]</span></p></li>
</ul>
<div class="fragment">
<ul>
<li><p>POMDP solution:</p>
<p><span class="math display">\[V^{\pi^r}(b) = \mathbb{E}\left[\sum_t C^r(s_t, u_t, a_t) \mid b_0 = b\right]\]</span></p>
<p><span class="math display">\[V^*(b) = \min_{\pi^r} V^{\pi^r}(b)\]</span></p></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><p>HOP approximation:</p>
<p><span class="math display">\[V^{\text{HS}}(b) = \mathbb{E}_b\left[\min_{\pi^r} V^{\pi^r}(s)\right]\]</span></p>
<p><span class="math display">\[= \mathbb{E}_g[V_g(x)]\]</span></p></li>
</ul>
</div>
</div><div class="column" style="width:65%;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/optimization.png" class="quarto-figure quarto-figure-center" width="500" height="400"></p>
</figure>
</div>
<div class="absolute small-math" style="bottom: 200px; right: 0px; ">
<p>Deterministic<br>
problem for<br>
each future</p>
</div>
</div>
</div></div>
</section>
<section id="results-video" class="slide level2">
<h2>Results (video)</h2>
<video id="video_shortcode_videojs_video1" width="800" height="500" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="https://www.cs.cmu.edu/~sjavdani/videos/rss_2015_hindsight_presentation.mp4"></video>
</section>
<section id="results" class="slide level2">
<h2>Results</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p>Compare with method that predicts one goal, the proposed method has:</p>
<ul>
<li><p>Faster execution time</p></li>
<li><p>Fewer user inputs</p></li>
</ul>
</div><div class="column" style="width:65%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/result-methods.jpg" class="quarto-figure quarto-figure-center" height="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="user-study" class="slide level2">
<h2>User Study</h2>

<img data-src="images/user-study.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="limitations" class="slide level2">
<h2>Limitations</h2>
<ul>
<li><p>Requires prior knowledge about the world:</p>
<ul>
<li><p>a dynamics model that predicts the consequences of taking a given action in a given state of the environment;</p></li>
<li><p>the set of possible goals for the user;</p></li>
<li><p>the user’s control policy given their goal.</p></li>
</ul></li>
<li><p>Suitable in constrained domains where where this knowledge can be directly hard-coded or learned.</p></li>
<li><p>Unsuitable for unstructured environments with ill-defined goals and unpredictable user behavior.</p></li>
</ul>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<ul>
<li><p>Javdani, S., Srinivasa, S. S., &amp; Bagnell, J. A. (2015). Shared autonomy via hindsight optimization. Robotics science and systems: online proceedings, 2015.</p></li>
<li><p>RSS2015 talk: “Shared autonomy via hindsight optimization”</p></li>
<li><p>Javdani, S., Admoni, H., Pellegrinelli, S., Srinivasa, S. S., &amp; Bagnell, J. A. (2018). Shared autonomy via hindsight optimization for teleoperation and teaming. The International Journal of Robotics Research, 37(7), 717-742.</p></li>
<li><p>ICAPS 2015 talk: “Hindsight Optimization for Probabilistic Planning with Factored Actions”</p></li>
</ul>
</section>
<section id="relaxedik-real-time-synthesis-of-accurate-and-feasible-robot-arm-motion" class="slide level2">
<h2>RelaxedIK: Real-time Synthesis of Accurate and Feasible Robot Arm Motion</h2>
</section>
<section id="recap-forward-kinematics-fk" class="slide level2">
<h2>Recap: Forward Kinematics (FK)</h2>
<ol type="1">
<li><p>Forward Kinematics</p>
<ul>
<li><p>A common robotic skeleton is a tree of rigid bones</p></li>
<li><p>The relative Euler angles of all the joints determine the end-effector</p>
<ul>
<li>End-effectors? A tool that’s connected to the end of a robot arm</li>
</ul>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="images/fk.png" height="100"></p>
<p><img data-src="images/twist-bend-twist.gif" height="200"></p>
</div><div class="column" style="width:65%;">
<p><img data-src="images/fk-robotarm.gif" height="300"></p>
</div></div></li>
</ul></li>
</ol>
<div class="tiny-font absolute" style="bottom: 0px; ">
<p>materials from <a href="https://github.com/alecjacobson/computer-graphics-csc418" class="uri">https://github.com/alecjacobson/computer-graphics-csc418</a></p>
</div>
</section>
<section id="recap-inverse-kinematics-ik" class="slide level2">
<h2>Recap: Inverse Kinematics (IK)</h2>
<ol type="1">
<li><p>Inverse Kinematics</p>
<ul>
<li><p>We formulate the inverse kinematics function as: <span class="math inline">\(\Theta = IK(p)\)</span> , which can be easily written in an analytic form for a simple tree skeleton.</p>
<ul>
<li><p>Pose contains velocity?</p></li>
<li><p>Hard to find feasible state space?</p></li>
</ul></li>
<li><p>In reality, IK is often treated as an optimization problem <span class="math display">\[
\chi_p(\Theta) = \| p_g - FK(\Theta) \|_2
\]</span></p></li>
</ul></li>
</ol>
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="images/hand-moving.gif" class="quarto-figure quarto-figure-right" height="200"></p>
</figure>
</div>
</section>
<section id="imitation-learning" class="slide level2">
<h2>Imitation Learning</h2>
<ol type="1">
<li><p>Imitation learning using IK</p>
<ul>
<li><p>Basic idea: Using IK to bridge between target pose and agent’s angles</p></li>
<li><p>Input: M (consecutive) expert (goal) poses</p></li>
<li><p>Output: M (consecutive) frames of agent’s euler joints</p></li>
<li><p>Constraints:</p>
<ul>
<li><p>IK constraints (goal constraints)</p></li>
<li><p>Between-frames constraints</p></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="imitation-learning-1" class="slide level2">
<h2>Imitation Learning</h2>
<ol type="1">
<li><p>Imitation learning using IK</p>
<ul>
<li>Basic idea: minimize the difference of target pose and agent pose</li>
</ul></li>
<li><p>Direct point-to-point approach</p>
<ul>
<li><p>TRAC-IK (previous state-of-the-art)</p></li>
<li><p>Pose2pose / frame2frame imitation learning</p>
<ul>
<li>Ignore most of the constraints between frames</li>
</ul></li>
<li><p>Problems</p>
<ul>
<li><p>Self-collision</p></li>
<li><p>Time constraints</p></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="imitation-learning-2" class="slide level2">
<h2>Imitation Learning</h2>
<p>Self-collision</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/self-collision.gif" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
</section>
<section id="imitation-learning-3" class="slide level2">
<h2>Imitation Learning</h2>
<p>Discontinuities</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/discontinuities.gif" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
</section>
<section id="imitation-learning-4" class="slide level2">
<h2>Imitation Learning</h2>
<p>Goal mistracking</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/goal-mistracking.gif" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
</section>
<section id="imitation-learning-5" class="slide level2">
<h2>Imitation Learning</h2>
<p>Unpredictable behaviors <img data-src="images/unpredictable.gif" class="quarto-figure quarto-figure-center" height="450"></p>
</section>
<section id="relaxed-ik" class="slide level2">
<h2>Relaxed IK</h2>
<ol type="1">
<li>Basic Idea: Using soft (Relaxed) IK loss that considers self-collision and singularity for faster optimization</li>
</ol>
<p><span class="math display">\[
f(\Theta) = \sum_{i=1}^{k} w_i f_i(\Theta, \Omega_i)
\]</span></p>
<ol type="1">
<li><p>Loss functions</p>
<ol type="a">
<li><p>End-effector position &amp; orientation matching</p></li>
<li><p>Minimize joint velocity, acceleration, jerk</p></li>
<li><p>Self-collision loss (fast)</p></li>
<li><p>Singularity loss</p></li>
</ol></li>
</ol>
</section>
<section id="relaxed-ik-1" class="slide level2">
<h2>Relaxed IK</h2>
<p>Self-collision loss</p>
<ul>
<li><p>Common approach: very slow</p></li>
<li><p>Relaxed IK:</p>
<ul>
<li><p>Approximate how imminent the robot is to a collision state</p></li>
<li><p>Using simulated data to train a network to predict the distances between links</p></li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math display">\[
\text{col}(\Theta) = \sum_{i,j} b \cdot \exp\left( -\frac{\text{dis}(l_i, l_j)^2}{2c^2} \right)
\]</span></p>
</div><div class="column" style="width:50%;">
<p><img data-src="images/collision-avoidance.gif"></p>
</div></div></li>
</ul>
</section>
<section id="relaxed-ik-2" class="slide level2">
<h2>Relaxed IK</h2>
<ol type="1">
<li>Singularity loss</li>
</ol>
<ul>
<li><p>Kinematic singularities are well studied in robotics</p></li>
<li><p>Relaxed IK:</p>
<ul>
<li><p>Find a metric that can approximate distance to a singularity</p></li>
<li><p>Jacobian’s condition number is used as a proxy distance to singularity<br>
Why?</p></li>
</ul>
<p><span class="math display">\[
\dot{\mathbf{x}} = \mathbf{J}(\Theta) \dot{\Theta}
\]</span></p>
<ul>
<li><p>Penalize condition values less than mean - b * std</p></li>
<li><p>Estimate mean, std from simulated data</p></li>
</ul></li>
</ul>
</section>
<section id="relaxed-ik-3" class="slide level2">
<h2>Relaxed IK</h2>
<p>Pros</p>
<ul>
<li>Much faster and smoother performance
<ul>
<li>combining neural network and traditional robotics</li>
</ul></li>
<li>Data driven, less human-engineering
<ul>
<li>novel singularity metric</li>
</ul></li>
<li>Easy to deploy
<ul>
<li>sim2Real</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/square-tracing.gif" class="quarto-figure quarto-figure-center" height="200"></p>
</figure>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="https://csc2626.github.io/website/" target="_blank" style="font-size:0.8em; bottom: -5px;">↩︎ Back to Course Website</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"src":"chalkboard.json","boardmarkerWidth":2,"chalkWidth":2,"chalkEffect":1},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/csc2626\.github\.io\/website\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script type="text/javascript" src="../custom_curtain.js"></script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    

</body></html>