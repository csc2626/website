---
title: "CSC2626 Imitation Learning for Robotics"
subtitle: "Week 12: Representation Learning for Imitation & Provable Generalization"
author: "Florian Shkurti"
format:
    revealjs:
        slide-number: true
        embed-resources: false
        show-notes: false
        smaller: true
        footer: '<a href="https://csc2626.github.io/website/" target="_blank">↩ Back to Course Website</a>'
        chalkboard:
            src: chalkboard.json
            buttons: true
            boardmarker-width: 2
            chalk-width: 2
            chalk-effect: 1.0
        css: ../style.css
html-math-method:
    method: mathjax
    url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

## Today’s Agenda

-   Representation Learning for Imitation

    -   Is it better to separate representation learning from policy learning?

-   Provable generalization

    -   PAC-Bayes generalization bounds

-   Robustness and safety

    -   Robustness as stability

## Learning dense representations for manipulation

{{< video https://www.youtube.com/watch?v=L5UW1VapKNE width="100%" height="65%" >}}

::: small-math
[Dense Object Nets: Learning Dense Visual Object Descriptors By and For Robotic Manipulation.]{.red} Florence, Manuelli, Tedrake. 2018
:::

## Learning policies on top of pretrained representations

{{< video https://www.youtube.com/watch?v=RBvaazKSOAc width="100%" height="65%" >}}

::: small-math
[Self-Supervised Correspondence in Visuomotor Policy Learning.]{.red} Florence, Manuelli, Tedrake. 2020
:::

## Another example of policy learning on pretrained representations

{{< video https://www.youtube.com/watch?v=bIzWADZjdoA width="100%" height="70%" >}}

## Can we show theoretically that representation learning helps?

\[switch to notes\]

## Today’s Agenda

::: grey-text
-   Representation Learning for Imitation

    -   Is it better to separate representation learning from policy learning?
:::

-   Provable generalization

    -   PAC-Bayes generalization bounds

-   Robustness and safety

    -   Robustness as stability

## PAC-Bayes generalization bounds

![](images/pac-bayes.png){fig-align="center"}

::: small-math
[PAC-Bayes Control: Learning Policies that Provably Generalize to New Environments.]{.red} Majumdar et al. 2020
:::

## PAC-Bayes Bound Applied to Control

![](images/pac-bayes2.png){fig-align="center"}

::: small-math
[PAC-Bayes Control: Learning Policies that Provably Generalize to New Environments.]{.red} Majumdar et al. 2020
:::

## PAC-Bayes Example

![](images/pac-bayes-ex.png){fig-align="center"}

::: small-math
[PAC-Bayes Control: Learning Policies that Provably Generalize to New Environments.]{.red} Majumdar et al. 2020
:::

## [PAC-Bayes Control for Visuomotor Policies]{.medium}

{{< video https://www.youtube.com/watch?v=nabtvOWoIlo width="100%" height="70%" >}}

::: small-math
[Generalization Guarantees for Imitation Learning.]{.red} Ren, Veer, Majumdar. CoRL 2020.
:::

## Today’s Agenda

::: grey-text
-   Representation Learning for Imitation

    -   Is it better to separate representation learning from policy learning?

-   Provable generalization

    -   PAC-Bayes generalization bounds
:::

-   Robustness and safety

    -   Robustness as stability

## What does it mean for a policy to be robust?

• The system (policy, dynamics) must be such that the policy will achieve its goal point, even if a family of disturbances/noise affect it

![](images/robust-policies.png){fig-align="center" height="350"}

::: {.small-math .absolute bottom="30%" right="10"}
Composition of robust policies

[LQR Trees.]{.red} Tedrake, RSS 2005.
:::

## Robustness as stability of dynamical systems

-   [Global asymptotic stability to a goal]{.red}: the region of attraction includes all states. The system will converge to the goal, no matter where it starts from.

<br>

-   How to ensure global asymptotic stability:
    -   Show that there exists a positive energy (Lyapunov) function that
    -   Decreases over time along the system trajectories
    -   And will become 0 at the convergence point

## Examples of Lyapunov functions

\[switches to notes\]

## [Two examples of learning Lyapunov functions]{.medium}

![](images/lyapunov-func.png){height="300"}

![](images/imitation-flow.png)

## Stability via Contraction Theory

{{< video https://www.youtube.com/watch?v=kmmJ6naGOfE width="100%" height="70%" >}}